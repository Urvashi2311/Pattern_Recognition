{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model bulit on colab is trained only on subset of 100 data samples"
      ],
      "metadata": {
        "id": "feeYTsVBKKED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV2FKvKXzVvv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import glob , csv , codecs , copy\n",
        "from tabulate import tabulate\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uRwn3EljiVei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff444161-b7be-4a19-cabc-12f9014f0c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang_list=['asm','ben','eng','guj','hin','kan', 'mal', 'mar', 'odi', 'pun', 'tam', 'tel']"
      ],
      "metadata": {
        "id": "ivw6vpCW0_3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Feature List"
      ],
      "metadata": {
        "id": "1IrVYWEFXrhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature(fpath,lang):\n",
        "  path = r'/content/drive/MyDrive/PRA2_data/extracted/'+lang+'/'+ fpath \n",
        "  # print(path)\n",
        "  all_files = glob.glob(path + \"/*.csv\")\n",
        "#   print(all_files)\n",
        "  mfcc_feature = np.empty([0,39])\n",
        "  count = 0\n",
        "  for filename in all_files:\n",
        "    if count < 100: # training using subset of 100 files per langauage\n",
        "      vectors = list(csv.reader(codecs.open(filename, 'rU', 'utf-16')))\n",
        "      mfcc_feature=np.concatenate((mfcc_feature,vectors),axis=0)\n",
        "      count+=1\n",
        "    else:\n",
        "      break\n",
        "  # print(\"Training Feature Collection for \" + lang+ \": \" ,mfcc_feature.shape)\n",
        "  return mfcc_feature"
      ],
      "metadata": {
        "id": "tKRQsFRe7DVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ubm_features(fpath):\n",
        "  for lang in lang_list:\n",
        "    path = r'/content/drive/MyDrive/PRA2_data/extracted/'+lang+'/'+ fpath\n",
        "    all_files = glob.glob(path + \"/*.csv\")\n",
        "      #   print(all_files)\n",
        "    mfcc_ubm_feature = np.empty([0,39])\n",
        "    count = 0\n",
        "    for filename in all_files:\n",
        "      if count < 100: # training using subset of 100 files per langauage\n",
        "        vectors = list(csv.reader(codecs.open(filename, 'rU', 'utf-16')))\n",
        "        mfcc_ubm_feature=np.concatenate((mfcc_ubm_feature,vectors),axis=0)\n",
        "        count+=1\n",
        "      else:\n",
        "        break\n",
        "    print(\"Training Feature Collection for \" + lang+ \": \" ,mfcc_ubm_feature.shape)\n",
        "  return mfcc_ubm_feature\n",
        "\n"
      ],
      "metadata": {
        "id": "QZsRkGYuzfrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_ubm_features('PB_train')"
      ],
      "metadata": {
        "id": "j-sjacEl19Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAP Adaption of Mean"
      ],
      "metadata": {
        "id": "RzputF3uX7cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def map_adapt(ubm, X, max_iter=100, r=0.7):\n",
        "    \n",
        "    gmm = copy.deepcopy(ubm)\n",
        "    # X=np,array(X,dtype=float)\n",
        "    for _ in range(max_iter):\n",
        "        n = np.sum(gmm.predict_proba(X), axis=0).reshape(-1, 1) # (K, 1)\n",
        "        X_tilde = (1 / n) * gmm.predict_proba(X).T.dot(X) # (K, F)\n",
        "        alpha = (n / (n + r)).reshape(-1, 1) # (K, 1)\n",
        "        gmm.means_ = alpha * X_tilde + (1 - alpha) * gmm.means_\n",
        "    \n",
        "    return gmm"
      ],
      "metadata": {
        "id": "P9r1TtA029w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models(ubm):   \n",
        "    \n",
        "    # To be a list of labeled models.\n",
        "    model_list = []\n",
        "    for lang in lang_list:\n",
        "        \n",
        "        features = np.array(get_feature('PB_train',lang),dtype=float)\n",
        "        \n",
        "        # Create and train GMM using MAP-adaptation.\n",
        "        gmm = map_adapt(ubm, features)\n",
        "        print(\"Model Adapted for \",lang)\n",
        "        # Add generated model to the list.\n",
        "        \n",
        "        model_list.append(gmm)\n",
        "\n",
        "    return model_list"
      ],
      "metadata": {
        "id": "YcNCyNum29sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model"
      ],
      "metadata": {
        "id": "djlFYbs17ujs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features_ubm = np.array(get_ubm_features('PB_train'),dtype=float)\n",
        "\n",
        "ubm = GaussianMixture(n_components=256,\n",
        "                      covariance_type='diag',\n",
        "                      max_iter=100, init_params='kmeans')\n",
        "\n",
        "ubm.fit(features_ubm)\n",
        "\n",
        "# n=np.sum(ubm.predict_proba(features_ubm)).reshape(-1,1)\n",
        "# X_tilde = (1 / n) * ubm.predict_proba(features_ubm).T.dot(features_ubm)\n",
        "\n",
        "models = get_models(ubm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAB8PNnm7o9y",
        "outputId": "15050252-0dd9-4231-d0bd-dde8ce8923d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Feature Collection for asm:  (11701, 39)\n",
            "Training Feature Collection for ben:  (23882, 39)\n",
            "Training Feature Collection for eng:  (35013, 39)\n",
            "Training Feature Collection for guj:  (25756, 39)\n",
            "Training Feature Collection for hin:  (23973, 39)\n",
            "Training Feature Collection for kan:  (21907, 39)\n",
            "Training Feature Collection for mal:  (19668, 39)\n",
            "Training Feature Collection for mar:  (33091, 39)\n",
            "Training Feature Collection for odi:  (22159, 39)\n",
            "Training Feature Collection for pun:  (37659, 39)\n",
            "Training Feature Collection for tam:  (32626, 39)\n",
            "Training Feature Collection for tel:  (24419, 39)\n",
            "Model Adapted for  asm\n",
            "Model Adapted for  ben\n",
            "Model Adapted for  eng\n",
            "Model Adapted for  guj\n",
            "Model Adapted for  hin\n",
            "Model Adapted for  kan\n",
            "Model Adapted for  mal\n",
            "Model Adapted for  mar\n",
            "Model Adapted for  odi\n",
            "Model Adapted for  pun\n",
            "Model Adapted for  tam\n",
            "Model Adapted for  tel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naD5UZ3eGXPq",
        "outputId": "9b614327-53cc-478c-a740-76dbfc1dbb9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256), GaussianMixture(covariance_type='diag', n_components=256)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Model"
      ],
      "metadata": {
        "id": "yposSl6wYGCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def testmodel(fpath,lang):\n",
        "  path = r'/content/drive/MyDrive/PRA2_data/extracted/'+lang+'/'+ fpath  \n",
        "  all_files = glob.glob(path + \"/*.csv\")  \n",
        "  pred_correct=0\n",
        "  lang_pred=[0] * len(lang_list)\n",
        "  count = 0\n",
        "  for filename in all_files:\n",
        "    if count<100: \n",
        "    \n",
        "      mfcc_test_feature = np.empty([0,39])\n",
        "      mfccs = list(csv.reader(codecs.open(filename, 'rU', 'utf-16')))\n",
        "      mfcc_test_feature=np.concatenate((mfcc_test_feature,mfccs),axis=0)      \n",
        "      # print(mfcc_test_feature.shape)\n",
        "      count+=1\n",
        "      log_likelihood = np.zeros(len(models))\n",
        "      # print(log_likelihood)\n",
        "      \n",
        "     \n",
        "      for i in range(len(models)):\n",
        "        gmm    = models[i]         #checking with each model one by one\n",
        "        scores = np.array(gmm.score_samples(mfcc_test_feature))        \n",
        "        log_likelihood[i] = scores.sum()\n",
        "\n",
        "      # print(log_likelihood)\n",
        "      l_index = np.argmax(log_likelihood)\n",
        "      lang_pred[l_index]+=1\n",
        "      if lang_list[l_index]==lang:\n",
        "        pred_correct+=1\n",
        "      # print (\"############################  Predicted Language - \", lang_list[l_index])\n",
        "      # print (\"############################  Actual Language - \", lang)        \n",
        "      \n",
        "    else:\n",
        "      break \n",
        "  \n",
        "\n",
        "  return pred_correct,count,lang_pred"
      ],
      "metadata": {
        "id": "Tnjmj5ItDq_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result for Prasar Bharti Data\n"
      ],
      "metadata": {
        "id": "9mUs0lRpFgbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_pb=[]\n",
        "confusion_mat_pb=[]\n",
        "for l in lang_list:\n",
        "  p,t,lang_pred=testmodel('PB_test',l)\n",
        "  res=[l,p,t]\n",
        "  confusion_mat_pb.append(lang_pred)\n",
        "  result_pb.append(res)\n",
        "print(\"System 2 GMM_UBM Prasar Bharti Sample test data:\")  \n",
        "head = [\"Language\",\"Predicted Correctly\",\"Total_Samples\"]\n",
        "print(tabulate(result_pb, headers=head, tablefmt=\"grid\"))\n",
        "# confusion_mat_pb\n",
        "# print(result_pb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGdwp4C2_yNQ",
        "outputId": "deeb3be9-ceed-4486-a9c2-a8c85f9c7da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System 2 GMM_UBM Prasar Bharti Sample test data:\n",
            "+------------+-----------------------+-----------------+\n",
            "| Language   |   Predicted Correctly |   Total_Samples |\n",
            "+============+=======================+=================+\n",
            "| asm        |                    75 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| ben        |                    97 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| eng        |                    88 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| guj        |                    91 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| hin        |                    75 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| kan        |                    79 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| mal        |                    77 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| mar        |                    65 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| odi        |                    91 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| pun        |                    54 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| tam        |                    82 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| tel        |                    86 |             100 |\n",
            "+------------+-----------------------+-----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Accuracy and Confusion Matrix for Prasar Bharti Data"
      ],
      "metadata": {
        "id": "8px2tOxFJoxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_correct=0\n",
        "total_samples=0\n",
        "for p in result_pb:\n",
        "  pred_correct+=p[1]\n",
        "  total_samples+=p[2]\n",
        "\n",
        "acc_pb= (pred_correct *100)/ total_samples\n",
        "print(\"Accuracy for Prasar Bharti Data Samples: \",acc_pb , \" %\")\n",
        "print(\"******************************************************************\")\n",
        "print(\"Confusion Matrix for Prasar Bharti Data: \")\n",
        "confusion_mat_pb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kdDTgXfDqRM",
        "outputId": "ce0b37bd-3ab1-477a-c8d7-f42b54647788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Prasar Bharti Data Samples:  80.0  %\n",
            "******************************************************************\n",
            "Confusion Matrix for Prasar Bharti Data: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[75, 1, 10, 1, 0, 0, 1, 1, 8, 0, 1, 2],\n",
              " [1, 97, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
              " [2, 1, 88, 0, 3, 0, 2, 0, 2, 0, 1, 1],\n",
              " [1, 0, 0, 91, 0, 0, 0, 1, 0, 1, 3, 3],\n",
              " [0, 1, 10, 7, 75, 0, 2, 3, 0, 2, 0, 0],\n",
              " [2, 0, 5, 0, 0, 79, 0, 1, 3, 1, 3, 6],\n",
              " [3, 2, 1, 2, 1, 0, 77, 1, 10, 0, 2, 1],\n",
              " [21, 0, 0, 0, 14, 0, 0, 65, 0, 0, 0, 0],\n",
              " [3, 0, 2, 0, 3, 0, 0, 0, 91, 0, 0, 1],\n",
              " [0, 0, 0, 46, 0, 0, 0, 0, 0, 54, 0, 0],\n",
              " [1, 5, 0, 11, 0, 0, 0, 1, 0, 0, 82, 0],\n",
              " [0, 1, 3, 5, 2, 0, 0, 0, 2, 0, 1, 86]]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result for Youtube Data"
      ],
      "metadata": {
        "id": "Y__VCbXV7ZEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_yt=[]\n",
        "confusion_mat_yt=[]\n",
        "for l in lang_list:\n",
        "  p,t,lang_pred=testmodel('YT_test',l)\n",
        "  res=[l,p,t]\n",
        "  confusion_mat_yt.append(lang_pred)\n",
        "  result_yt.append(res)\n",
        "print(\"System 2 GMM_UBM Youtube Sample test data:\")\n",
        "head = [\"Language\",\"Predicted Correctly\",\"Total_Samples\"]\n",
        "print(tabulate(result_yt, headers=head, tablefmt=\"grid\"))\n",
        "# confusion_mat_yt\n",
        "# print(result_yt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-3szG6f7f09",
        "outputId": "2200594d-9a3e-4271-a9ba-161c5f00c379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "System 2 GMM_UBM Prasar Bharti Sample test data:\n",
            "+------------+-----------------------+-----------------+\n",
            "| Language   |   Predicted Correctly |   Total_Samples |\n",
            "+============+=======================+=================+\n",
            "| asm        |                    24 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| ben        |                    10 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| eng        |                    17 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| guj        |                     1 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| hin        |                     1 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| kan        |                     5 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| mal        |                     4 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| mar        |                    25 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| odi        |                     9 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| pun        |                     0 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| tam        |                    11 |             100 |\n",
            "+------------+-----------------------+-----------------+\n",
            "| tel        |                     1 |             100 |\n",
            "+------------+-----------------------+-----------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Accuracy and Confusion Matrix for Youtube Data"
      ],
      "metadata": {
        "id": "vrN9m7Bg7u1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_correct=0\n",
        "total_samples=0\n",
        "for p in result_yt:\n",
        "  pred_correct+=p[1]\n",
        "  total_samples+=p[2]\n",
        "\n",
        "acc_yt= (pred_correct *100)/ total_samples\n",
        "print(\"Accuracy for Youtube Data Samples: \",acc_yt , \" %\")\n",
        "print(\"******************************************************************\")\n",
        "print(\"Confusion Matrix for Youtube Data: \")\n",
        "confusion_mat_yt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFijvP3I7_K3",
        "outputId": "e0dd7eb4-b92b-421f-f1a1-18442b54811f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Youtube Data Samples:  9.0  %\n",
            "******************************************************************\n",
            "Confusion Matrix for Youtube Data: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[24, 21, 12, 0, 0, 0, 4, 1, 35, 0, 0, 3],\n",
              " [8, 10, 18, 0, 0, 3, 28, 15, 8, 0, 0, 10],\n",
              " [1, 7, 17, 0, 0, 9, 27, 4, 13, 0, 20, 2],\n",
              " [0, 0, 9, 1, 0, 17, 54, 4, 0, 0, 8, 7],\n",
              " [0, 22, 0, 1, 1, 8, 34, 4, 19, 0, 2, 9],\n",
              " [13, 15, 13, 0, 0, 5, 14, 22, 12, 0, 5, 1],\n",
              " [6, 21, 0, 12, 3, 6, 4, 21, 7, 6, 10, 4],\n",
              " [18, 0, 2, 0, 0, 0, 16, 25, 12, 0, 0, 27],\n",
              " [22, 12, 16, 0, 0, 0, 5, 36, 9, 0, 0, 0],\n",
              " [4, 2, 0, 0, 0, 3, 4, 28, 58, 0, 1, 0],\n",
              " [7, 12, 3, 1, 24, 0, 5, 8, 25, 4, 11, 0],\n",
              " [1, 7, 0, 16, 2, 2, 22, 16, 18, 0, 15, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}